## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class', parms = list(split = "information"))
# Plot the tree using prp command defined in rpart.plot package
t_pred = predict(rtree.dt_a,test,type="class")
mean(test$Q41.Sex == t_pred)
prp(rtree.dt_a, main = c('accuracy_rates',round(mean(test$Q41.Sex == t_pred), digits = 2)))
})
output$h2 <- renderPlotly({
dt_2 <- fread('cn_h2.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_2))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_2)), size = smp_size)
train <- dt_2[train_ind, ]
test <- dt_2[-train_ind, ]
linear_2 <- lm(con_inno ~ sus_aes, data = train)
p_lm <- predict(linear_2, test)
actuals_preds <- data.frame(cbind(actuals=test$con_inno, predicteds=p_lm))
correlation_accuracy <- cor(actuals_preds)[1,2]
ggplotRegression(linear_2, correlation_accuracy)
})
output$h3 <- renderPlotly({
dt_3 <- fread('cn_h3.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_3))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_3)), size = smp_size)
train <- dt_3[train_ind, ]
test <- dt_3[-train_ind, ]
linear_3 <- lm(green_con ~ sus_val, data = train)
p_lm <- predict(linear_3, test)
actuals_preds <- data.frame(cbind(actuals=test$green_con, predicteds=p_lm))
correlation_accuracy <- cor(actuals_preds)[1,2]
ggplotRegression(linear_3, correlation_accuracy)
})
output$summary <- renderPrint({
dt <- fread('knn_imputed_cn_data.csv')[,-1]
dt <- dt[,37:56]
table_one <- arsenal::tableby(~.,dt)
summary(dt)
})
}
# Run the application
shinyApp(ui = ui, server = server)
#deployApp()
################### scatter plot function: ggplotRegression ###################
ggplotRegression <- function (fit, correlation_accuracy) {
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5)
" Accuarcy rate=", round(correlation_accuracy, digits = 2)))
}
" Accuarcy rate=", round(correlation_accuracy, digits = 2))
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5)
" Accuarcy rate=", round(correlation_accuracy, digits = 2)))
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5),
" Accuarcy rate=", round(correlation_accuracy, digits = 2)))
################### scatter plot function: ggplotRegression ###################
ggplotRegression <- function (fit, correlation_accuracy) {
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5),
" Accuarcy rate=", round(correlation_accuracy, digits = 2)))
}
dt_2 <- fread('cn_h2.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_2))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_2)), size = smp_size)
train <- dt_2[train_ind, ]
test <- dt_2[-train_ind, ]
linear_2 <- lm(con_inno ~ sus_aes, data = train)
p_lm <- predict(linear_2, test)
actuals_preds <- data.frame(cbind(actuals=test$con_inno, predicteds=p_lm))
correlation_accuracy <- cor(actuals_preds)[1,2]
ggplotRegression(linear_2, correlation_accuracy)
runApp()
deployApp()
## Junjie Wu
## China Survey Analysis
rm(list = ls())
pacman::p_load(data.table, bit64, openxlsx, haven, dplyr, corrplot, zoo,
matrixStats, plotly, DAAG,PerformanceAnalytics,
BiocManager, ISLR, tree, rpart,rpart.plot, arsenal)
setwd('~/Desktop/GLIS Research/GLIS_research_project/data')
###################### missing value imputation #####################
# dt <- fread('cleaned_01_16_cn.csv')
# #knn
# if(exists(".Random.seed")) rm(.Random.seed)
#
# dt_imputed <- impute.knn(as.matrix(dt[,c(2:30, 38:69, 71)]))
# dt_q30 <- dt[,c(1,31:37)]
#
# dt_imputed <- data.table(dt_imputed$data)
# dt_imputed$V1 <- seq.int(nrow(dt_imputed))
#
# dt_merge <- merge(dt_imputed, dt_q30, by = 'V1')
#
# dt_merged <- dt_merge[,c(1:30,64:70,31:63)]
#
# write.csv(dt_merged, 'knn_imputed_cn_data.csv', row.names = F)
# ####################################################################
dt <- fread('knn_imputed_cn_data.csv')[,-1]
# dt_csv_mean <- sapply(dt[,37:56], mean, na.rm=TRUE)
#
#
# View(sort(dt_csv_mean, decreasing = T))
# sustainable value
dt[, `:=`(sus_val = rowSums(.SD, na.rm=T)), .SDcols=c(41,49:56)]
# aesthetic values
dt[, aes_val := rowSums(.SD, na.rm=T), .SDcols=c(42:43)]
#Green Consciousness
dt[, green_con := rowSums(.SD, na.rm=T), .SDcols=c(1:5)]
#Consumer Innovativeness
dt[, con_inno := rowSums(.SD, na.rm=T), .SDcols=c(50:56, 58:62)]
################### scatter plot function: ggplotRegression ###################
ggplotRegression <- function (fit) {
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5)))
}
#descriptive analysis
dt_mean <- sapply(dt[,38:57], mean, na.rm=TRUE)
summary(dt)
sort(dt_mean)
table_one <- tableby(~.,dt)
summary(table_one,text=TRUE)
#write.table(table_one, '../script/cn_preliminary_analysis/cn_h1.csv')
################################################################################
######################### Q1 ###############################
dt_individual <- dt[, c(65,41,49:56,42:43)]
ncol(dtdt_individual)
ncol(dt_individual)
## Junjie Wu
## cn_preliminary_analysis Shiny App
rm(list = ls())
#setwd('~/Desktop/GLIS Research/GLIS_research_project/script/cn_preliminary_analysis')
library(rsconnect)
library(data.table)
library(shiny)
library(rpart)
library(rpart.plot)
library(plotly)
library(arsenal)
library(ggplot2)
# Define UI for application
ui <-
navbarPage("cn_preliminary_analysis",
tabPanel("H1 Decision Tree: Individual Response",
mainPanel(
plotOutput("h1_ind")
)
),
tabPanel("H1 Decision Tree: aes and sus score",
mainPanel(
plotOutput("h1_sum")
)
),
tabPanel("H2 Linear Regression",
mainPanel(
plotlyOutput("h2")
)
),
tabPanel("H3 Linear Regression",
mainPanel(
plotlyOutput("h3")
)
),
tabPanel('Descriptive Analysis: Q31 & Q38',
verbatimTextOutput('summary'))
)
# Define server logic required to draw a histogram
server <- function(input, output) {
################### scatter plot function: ggplotRegression ###################
ggplotRegression <- function (fit, correlation_accuracy) {
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5),
" Accuarcy rate=", round(correlation_accuracy, digits = 2)))
}
output$h1_ind <- renderPlot({
dt_a <- fread('cn_h1_ind.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class')
# Plot the tree using prp command defined in rpart.plot package
t_pred = predict(rtree.dt_a,test,type="class")
mean(test$Q41.Sex == t_pred)
prp(rtree.dt_a, main = c('accuracy_rate',round(mean(test$Q41.Sex == t_pred), digits = 2)))
dt_a <- fread('cn_h1_ind.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
dt_a <- fread('cn_h1_ind.csv')
etwd('~/Desktop/GLIS Research/GLIS_research_project/script/cn_preliminary_analysis')
setwd('~/Desktop/GLIS Research/GLIS_research_project/script/cn_preliminary_analysis')
dt_a <- fread('cn_h1_ind.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class')
# Plot the tree using prp command defined in rpart.plot package
t_pred = predict(rtree.dt_a,test,type="class")
mean(test$Q41.Sex == t_pred)
prp(rtree.dt_a, main = c('accuracy_rate',round(mean(test$Q41.Sex == t_pred), digits = 2)))
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'anova')
# Plot the tree using prp command defined in rpart.plot package
t_pred = predict(rtree.dt_a,test,type="class")
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'anova')
train
rpart(Q41.Sex ~ ., data=train, method = 'anova')
dt_a <- fread('cn_h1_ind.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
is.na(dt_a)
unique(is.na(dt_a))
count(is.na(dt_a))
is.na(dt_a) == F
dt_a <- fread('cn_h1_ind.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'anova')
rpart(Q41.Sex ~ ., data=train, method = 'anova')
apply(dt_a, 2, function(x) any(is.na(x)))
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'anova')
dt_a <- fread('cn_h1_ind.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
## Junjie Wu
## China Survey Analysis
rm(list = ls())
pacman::p_load(data.table, bit64, openxlsx, haven, dplyr, corrplot, zoo,
matrixStats, plotly, DAAG,PerformanceAnalytics,
BiocManager, ISLR, tree, rpart,rpart.plot, arsenal)
setwd('~/Desktop/GLIS Research/GLIS_research_project/data')
###################### missing value imputation #####################
# dt <- fread('cleaned_01_16_cn.csv')
# #knn
# if(exists(".Random.seed")) rm(.Random.seed)
#
# dt_imputed <- impute.knn(as.matrix(dt[,c(2:30, 38:69, 71)]))
# dt_q30 <- dt[,c(1,31:37)]
#
# dt_imputed <- data.table(dt_imputed$data)
# dt_imputed$V1 <- seq.int(nrow(dt_imputed))
#
# dt_merge <- merge(dt_imputed, dt_q30, by = 'V1')
#
# dt_merged <- dt_merge[,c(1:30,64:70,31:63)]
#
# write.csv(dt_merged, 'knn_imputed_cn_data.csv', row.names = F)
# ####################################################################
dt <- fread('knn_imputed_cn_data.csv')[,-1]
# dt_csv_mean <- sapply(dt[,37:56], mean, na.rm=TRUE)
#
#
# View(sort(dt_csv_mean, decreasing = T))
# sustainable value
dt[, `:=`(sus_val = rowSums(.SD, na.rm=T)), .SDcols=c(41,49:56)]
# aesthetic values
dt[, aes_val := rowSums(.SD, na.rm=T), .SDcols=c(42:43)]
#Green Consciousness
dt[, green_con := rowSums(.SD, na.rm=T), .SDcols=c(1:5)]
#Consumer Innovativeness
dt[, con_inno := rowSums(.SD, na.rm=T), .SDcols=c(50:56, 58:62)]
################### scatter plot function: ggplotRegression ###################
ggplotRegression <- function (fit) {
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5)))
}
#descriptive analysis
dt_mean <- sapply(dt[,38:57], mean, na.rm=TRUE)
summary(dt)
sort(dt_mean)
table_one <- tableby(~.,dt)
summary(table_one,text=TRUE)
#write.table(table_one, '../script/cn_preliminary_analysis/cn_h1.csv')
################################################################################
######################### Q1 ###############################
dt_individual <- dt[, c(65,41,49:56,42:43)]
dt_individual <- dt_individual[Q41.Sex < 3,]
dt_a <- dt_individual
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
train
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'anova')
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
dt_individual <- dt_individual[Q41.Sex < 3,]
dt_individual <- dt[, c(65,41,49:56,42:43)]
dt_individual <- dt_individual[Q41.Sex < 3,]
dt_individual$Q41.Sex <- as.factor(ifelse(dt_individual$Q41.Sex<=1, "Male", "Female"))
dt_a <- dt_individual
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class')
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
dt_individual <- dt[, c(65,41,49:56,42:43)]
dt_individual <- dt_individual[Q41.Sex < 3,]
dt_individual$Q41.Sex <- as.factor(ifelse(dt_individual$Q41.Sex<=1, "Male", "Female"))
#write.csv(dt_individual, '../script/cn_preliminary_analysis/cn_h1_ind.csv', row.names = F)
dt_aes_sus  <- dt[, c(65,70,71)]
dt_aes_sus <- dt_aes_sus[Q41.Sex < 3,]
dt_aes_sus$Q41.Sex <- as.factor(ifelse(dt_aes_sus$Q41.Sex<=1, "Male", "Female"))
#write.csv(dt_aes_sus, '../script/cn_preliminary_analysis/cn_h1_sum.csv', row.names = F)
dt_a <- dt_individual
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class')
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class', minbucket = 3)
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class', minbucket = 1)
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class', minsplit = 10)
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class', minsplit = 5)
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
## Junjie Wu
## China Survey Analysis
rm(list = ls())
pacman::p_load(data.table, bit64, openxlsx, haven, dplyr, corrplot, zoo,
matrixStats, plotly, DAAG,PerformanceAnalytics,
BiocManager, ISLR, tree, rpart,rpart.plot, arsenal)
setwd('~/Desktop/GLIS Research/GLIS_research_project/data')
###################### missing value imputation #####################
# dt <- fread('cleaned_01_16_cn.csv')
# #knn
# if(exists(".Random.seed")) rm(.Random.seed)
#
# dt_imputed <- impute.knn(as.matrix(dt[,c(2:30, 38:69, 71)]))
# dt_q30 <- dt[,c(1,31:37)]
#
# dt_imputed <- data.table(dt_imputed$data)
# dt_imputed$V1 <- seq.int(nrow(dt_imputed))
#
# dt_merge <- merge(dt_imputed, dt_q30, by = 'V1')
#
# dt_merged <- dt_merge[,c(1:30,64:70,31:63)]
#
# write.csv(dt_merged, 'knn_imputed_cn_data.csv', row.names = F)
# ####################################################################
dt <- fread('knn_imputed_cn_data.csv')[,-1]
# dt_csv_mean <- sapply(dt[,37:56], mean, na.rm=TRUE)
#
#
# View(sort(dt_csv_mean, decreasing = T))
# sustainable value
dt[, `:=`(sus_val = rowSums(.SD, na.rm=T)), .SDcols=c(41,49:56)]
# aesthetic values
dt[, aes_val := rowSums(.SD, na.rm=T), .SDcols=c(42:43)]
#Green Consciousness
dt[, green_con := rowSums(.SD, na.rm=T), .SDcols=c(1:5)]
#Consumer Innovativeness
dt[, con_inno := rowSums(.SD, na.rm=T), .SDcols=c(50:56, 58:62)]
################### scatter plot function: ggplotRegression ###################
ggplotRegression <- function (fit) {
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5)))
}
#descriptive analysis
dt_mean <- sapply(dt[,38:57], mean, na.rm=TRUE)
summary(dt)
sort(dt_mean)
table_one <- tableby(~.,dt)
summary(table_one,text=TRUE)
#write.table(table_one, '../script/cn_preliminary_analysis/cn_h1.csv')
################################################################################
######################### Q1 ###############################
dt_individual <- dt[, c(65,41,49:56,42:43)]
dt_individual <- dt_individual[Q41.Sex < 3,]
dt_individual$Q41.Sex <- as.factor(ifelse(dt_individual$Q41.Sex<=1, "Male", "Female"))
#write.csv(dt_individual, '../script/cn_preliminary_analysis/cn_h1_ind.csv', row.names = F)
dt_aes_sus  <- dt[, c(65,70,71)]
dt_aes_sus <- dt_aes_sus[Q41.Sex < 3,]
dt_aes_sus$Q41.Sex <- as.factor(ifelse(dt_aes_sus$Q41.Sex<=1, "Male", "Female"))
#write.csv(dt_aes_sus, '../script/cn_preliminary_analysis/cn_h1_sum.csv', row.names = F)
dt_a <- dt_individual
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class', minsplit = 5)
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
train
rtree.dt_a = rpart(Q41.Sex ~ ., data=dt_a, method = 'class', minsplit = 5)
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
rtree.dt_a = rpart(Q41.Sex ~ ., data=dt_a, method = 'class', minsplit =15)
rtree.dt_a = rpart(Q41.Sex ~ ., data=dt_a, method = 'class', minsplit =5)
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
rtree.dt_a = rpart(Q41.Sex ~ ., data=dt_a, method = 'class', minsplit =5)
# Plot the tree using prp command defined in rpart.plot package
prp(rtree.dt_a)
tree.dt_a = tree(Q41.Sex~., data=dt_a, control = tree.control(mincut = 2))
tree.dt_a = tree(Q41.Sex~., data=dt_a, control = tree.control(nobs,mincut = 2))
tree.dt_a = tree(Q41.Sex~., data=dt_a, mincut=2)
plot(tree.dt_a)
text(tree.dt_a, pretty = 0)
rtree.dt_a = rpart(Q41.Sex ~ ., data=dt_a, method = 'class')
