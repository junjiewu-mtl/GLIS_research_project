dt_a <- fread('cn_h1_ind.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class',   minsplit = 2,
minbucket = 1,
cp = 0.008)
# Plot the tree using prp command defined in rpart.plot package
t_pred = predict(rtree.dt_a,test,type="class")
fancyRpartPlot(rtree.dt_a, main = c('accuracy_rate',round(mean(test$Q41.Sex == t_pred), digits = 2)))
})
output$h1_sum <- renderPlot({
dt_a <- fread('cn_h1_sum.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class', parms = list(split = "information"))
# Plot the tree using prp command defined in rpart.plot package
t_pred = predict(rtree.dt_a,test,type="class")
mean(test$Q41.Sex == t_pred)
fancyRpartPlot(rtree.dt_a, main = c('accuracy_rate',round(mean(test$Q41.Sex == t_pred), digits = 2)))
})
output$h2 <- renderPlotly({
dt_2 <- fread('cn_h2.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_2))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_2)), size = smp_size)
train <- dt_2[train_ind, ]
test <- dt_2[-train_ind, ]
linear_2 <- lm(con_inno ~ sus_aes, data = train)
p_lm <- predict(linear_2, test)
actuals_preds <- data.frame(cbind(actuals=test$con_inno, predicteds=p_lm))
correlation_accuracy <- cor(actuals_preds)[1,2]
ggplotRegression(linear_2, correlation_accuracy)
})
output$h3 <- renderPlotly({
dt_3 <- fread('cn_h3.csv')
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_3))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_3)), size = smp_size)
train <- dt_3[train_ind, ]
test <- dt_3[-train_ind, ]
linear_3 <- lm(green_con ~ sus_val, data = train)
p_lm <- predict(linear_3, test)
actuals_preds <- data.frame(cbind(actuals=test$green_con, predicteds=p_lm))
correlation_accuracy <- cor(actuals_preds)[1,2]
ggplotRegression(linear_3, correlation_accuracy)
})
output$summary <- renderPrint({
dt <- fread('knn_imputed_cn_data.csv')[,-1]
dt <- dt[,37:56]
table_one <- arsenal::tableby(~.,dt)
summary(dt)
})
}
# Run the application
shinyApp(ui = ui, server = server)
rsconnect::setAccountInfo(name='junjie', token='74938FEFFAEF75EA6E54700782BB0390', secret='Jkoe5jxkI/2qS2i2Q8iDUVYRDzpuHIDIRPOWyg2H')
deployApp()
# Run the application
shinyApp(ui = ui, server = server)
runApp('~/Desktop/GLIS Research/GLIS_research_project/script/cn_preliminary_analysis')
## Junjie Wu
## China Survey Analysis
rm(list = ls())
pacman::p_load(data.table, bit64, openxlsx, haven, dplyr, corrplot, zoo,
matrixStats, plotly, DAAG,PerformanceAnalytics,
BiocManager, ISLR, tree, rpart,rpart.plot, arsenal, rattle,
RColorBrewer)
setwd('~/Desktop/GLIS Research/GLIS_research_project/data')
###################### missing value imputation #####################
# dt <- fread('cleaned_01_16_cn.csv')
# #knn
# if(exists(".Random.seed")) rm(.Random.seed)
#
# dt_imputed <- impute.knn(as.matrix(dt[,c(2:30, 38:69, 71)]))
# dt_q30 <- dt[,c(1,31:37)]
#
# dt_imputed <- data.table(dt_imputed$data)
# dt_imputed$V1 <- seq.int(nrow(dt_imputed))
#
# dt_merge <- merge(dt_imputed, dt_q30, by = 'V1')
#
# dt_merged <- dt_merge[,c(1:30,64:70,31:63)]
#
# write.csv(dt_merged, 'knn_imputed_cn_data.csv', row.names = F)
# ####################################################################
dt <- fread('knn_imputed_cn_data.csv')[,-1]
# dt_csv_mean <- sapply(dt[,37:56], mean, na.rm=TRUE)
#
#
# View(sort(dt_csv_mean, decreasing = T))
# sustainable value
dt[, `:=`(sus_val = rowSums(.SD, na.rm=T)), .SDcols=c(41,49:56)]
# aesthetic values
dt[, aes_val := rowSums(.SD, na.rm=T), .SDcols=c(42:43)]
#Green Consciousness
dt[, green_con := rowSums(.SD, na.rm=T), .SDcols=c(1:5)]
#Consumer Innovativeness
dt[, con_inno := rowSums(.SD, na.rm=T), .SDcols=c(50:56, 58:62)]
################### scatter plot function: ggplotRegression ###################
ggplotRegression <- function (fit) {
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5)))
}
#descriptive analysis
dt_mean <- sapply(dt[,38:57], mean, na.rm=TRUE)
summary(dt)
sort(dt_mean)
table_one <- tableby(~.,dt)
summary(table_one,text=TRUE)
#write.table(table_one, '../script/cn_preliminary_analysis/cn_h1.csv')
################################################################################
######################### Q1 ###############################
dt_individual <- dt[, c(65,41,49:56,42:43)]
dt_individual <- dt_individual[Q41.Sex < 3,]
dt_individual$Q41.Sex <- as.factor(ifelse(dt_individual$Q41.Sex<=1, "Male", "Female"))
#write.csv(dt_individual, '../script/cn_preliminary_analysis/cn_h1_ind.csv', row.names = F)
dt_aes_sus  <- dt[, c(65,70,71)]
dt_aes_sus <- dt_aes_sus[Q41.Sex < 3,]
dt_aes_sus$Q41.Sex <- as.factor(ifelse(dt_aes_sus$Q41.Sex<=1, "Male", "Female"))
#write.csv(dt_aes_sus, '../script/cn_preliminary_analysis/cn_h1_sum.csv', row.names = F)
dt_a <- dt_individual
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class',   minsplit = 2,
minbucket = 1,
cp = 0.008)
## Junjie Wu
## China Survey Analysis
rm(list = ls())
pacman::p_load(data.table, bit64, openxlsx, haven, dplyr, corrplot, zoo,
matrixStats, plotly, DAAG,PerformanceAnalytics,
BiocManager, ISLR, tree, rpart,rpart.plot, arsenal, rattle,
RColorBrewer)
setwd('~/Desktop/GLIS Research/GLIS_research_project/data')
###################### missing value imputation #####################
# dt <- fread('cleaned_01_16_cn.csv')
# #knn
# if(exists(".Random.seed")) rm(.Random.seed)
#
# dt_imputed <- impute.knn(as.matrix(dt[,c(2:30, 38:69, 71)]))
# dt_q30 <- dt[,c(1,31:37)]
#
# dt_imputed <- data.table(dt_imputed$data)
# dt_imputed$V1 <- seq.int(nrow(dt_imputed))
#
# dt_merge <- merge(dt_imputed, dt_q30, by = 'V1')
#
# dt_merged <- dt_merge[,c(1:30,64:70,31:63)]
#
# write.csv(dt_merged, 'knn_imputed_cn_data.csv', row.names = F)
# ####################################################################
dt <- fread('knn_imputed_cn_data.csv')[,-1]
# dt_csv_mean <- sapply(dt[,37:56], mean, na.rm=TRUE)
#
#
# View(sort(dt_csv_mean, decreasing = T))
# sustainable value
dt[, `:=`(sus_val = rowSums(.SD, na.rm=T)), .SDcols=c(41,49:56)]
# aesthetic values
dt[, aes_val := rowSums(.SD, na.rm=T), .SDcols=c(42:43)]
#Green Consciousness
dt[, green_con := rowSums(.SD, na.rm=T), .SDcols=c(1:5)]
#Consumer Innovativeness
dt[, con_inno := rowSums(.SD, na.rm=T), .SDcols=c(50:56, 58:62)]
################### scatter plot function: ggplotRegression ###################
ggplotRegression <- function (fit) {
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5)))
}
#descriptive analysis
dt_mean <- sapply(dt[,38:57], mean, na.rm=TRUE)
summary(dt)
sort(dt_mean)
table_one <- tableby(~.,dt)
summary(table_one,text=TRUE)
#write.table(table_one, '../script/cn_preliminary_analysis/cn_h1.csv')
################################################################################
######################### Q1 ###############################
dt_individual <- dt[, c(65,41,49:56,42:43)]
dt_individual <- dt_individual[Q41.Sex < 3,]
dt_individual$Q41.Sex <- as.factor(ifelse(dt_individual$Q41.Sex<=1, "Male", "Female"))
#write.csv(dt_individual, '../script/cn_preliminary_analysis/cn_h1_ind.csv', row.names = F)
dt_aes_sus  <- dt[, c(65,70,71)]
dt_aes_sus <- dt_aes_sus[Q41.Sex < 3,]
dt_aes_sus$Q41.Sex <- as.factor(ifelse(dt_aes_sus$Q41.Sex<=1, "Male", "Female"))
#write.csv(dt_aes_sus, '../script/cn_preliminary_analysis/cn_h1_sum.csv', row.names = F)
dt_a <- dt_individual
## 75% of the sample size
smp_size <- floor(0.75 * nrow(dt_a))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dt_a)), size = smp_size)
train <- dt_a[train_ind, ]
test <- dt_a[-train_ind, ]
# regression tree
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class',   minsplit = 2,
minbucket = 1,
cp = 0.008)
# Plot the tree using prp command defined in rpart.plot package
fancyRpartPlot(rtree.dt_a)
zp <- prune(rtree.dt_a, cp = 0.1)
# Plot the tree using prp command defined in rpart.plot package
fancyRpartPlot(zp)
zp
zp <- prune(rtree.dt_a, cp = 0.01)
summary(zp)
# Plot the tree using prp command defined in rpart.plot package
fancyRpartPlot(zp)
zp <- prune(rtree.dt_a, cp = 0.1)
summary(zp)
# Plot the tree using prp command defined in rpart.plot package
fancyRpartPlot(zp)
rtree.dt_a = rpart(Q41.Sex ~ ., data=train, method = 'class',   minsplit = 2,
minbucket = 1,
cp = 0.008)
summary(rtree.dt_a)
# Plot the tree using prp command defined in rpart.plot package
fancyRpartPlot(rtree.dt_a)
library(statsr)
library(tidyverse)
library(statsr)
library(tidyverse)
library(statsr)
data(brfss)
library(tidyverse)
library(tidyverse)
<div class="instructions">
Complete all **Exercises**, and submit answers to **Questions** in the **Quiz: Week 2 Lab** on Coursera.
</div>
## Getting Started
### Load packages
In this lab we will explore some basic Bayesian inference using conjugate priors
and credible intervals to examine some categorical and count data from the
[CDC's Behavioral Risk Factor Surveillance System](http://www.cdc.gov/brfss/)
(BRFSS). A subset of these data from 2013 have been made available in the
`statsr` package, as usual we will first load the package and then the data set.
Let's load the package,
```{r load-packages, message=FALSE}
library(statsr)
data(brfss)
library(statsr)
data(brfss)
library(tidyverse)
force(brfss)
colnames(brfss)
credible_interval_app()
table(brfss$exercise)
summary(brfss$exercise)
brfss$exercise
credible_interval_app()
table(brfss$exercise)
table(brfss$exercise)
credible_interval_app()
n <- length(brfss$exercise)
x <- sum(brfss$exercise == "YES")
n <- length(brfss$exercise)
x <- sum(brfss$exercise == "YES")
table(brfss$exercise)
x <- sum(brfss$exercise == "Yes")
n <- length(brfss$exercise)
x <- sum(brfss$exercise == "Yes")
mean(x)
mean(x/n)
var(x)
credible_interval_app()
n-x
credible_interval_app()
library(tidyverse)
library(statsr)
data(brfss)
credible_interval_app()
(brfss$exercise)
credible_interval_app()
brfss$fruit_per_day
len(brfss$fruit_per_day))
len(brfss$fruit_per_day)
length(brfss$fruit_per_day)
a <- sum(length(brfss$fruit_per_day))
a <- sum(brfss$fruit_per_day)
credible_interval_app()
brfss$vege_per_day
length(brfss$vege_per_day)
sum(brfss$vege_per_day)
credible_interval_app()
pacman::p_load(Rlinkedin)
library(devtools)
pacman::p_load(Rlinkedin,devtools)
library(devtools)
install_github("mpiccirilli/Rlinkedin")
library(Rlinkedin)
# To use your own application's API and Secret Key:
in.auth <- inOAuth("GLIS 611 Research", "784svyhvbb1nww", "X6mnE7ziObAKhddc")
# To use the default API and Secret Key for the Rlinkedin package:
in.auth <- inOAuth()
# To use your own application's API and Secret Key:
in.auth <- inOAuth("GLIS 611 Research", "784svyhvbb1nww", "X6mnE7ziObAKhddc")
# To use your own application's API and Secret Key:
in.auth <- inOAuth("GLIS 611 Research", "784svyhvbb1nww", "X6mnE7ziObAKhddc")
my.connections <- getMyConnections(in.auth)
pacman::p_load(Rlinkedin,devtools)
library(devtools)
install_github("mpiccirilli/Rlinkedin")
library(Rlinkedin)
# To use the default API and Secret Key for the Rlinkedin package:
in.auth <- inOAuth()
# To use your own application's API and Secret Key:
in.auth <- inOAuth("GLIS 611 Research", "784svyhvbb1nww", "X6mnE7ziObAKhddc")
library(Rlinkedin)
# To use the default API and Secret Key for the Rlinkedin package:
in.auth <- inOAuth()
library(Rlinkedin)
# To use the default API and Secret Key for the Rlinkedin package:
#in.auth <- inOAuth()
# To use your own application's API and Secret Key:
in.auth <- inOAuth("GLIS 611 Research", "784svyhvbb1nww", "X6mnE7ziObAKhddc")
# To use the default API and Secret Key for the Rlinkedin package:
in.auth <- inOAuth()
my.connections <- getMyConnections(in.auth)
my.connections <- getMyConnections(in.auth)
rm(list = ls())
pacman::p_load(data.table, bit64, openxlsx, haven, dplyr, corrplot, zoo,
matrixStats, plotly, DAAG,PerformanceAnalytics,
BiocManager, ISLR, tree, rpart,rpart.plot, arsenal, rattle,
RColorBrewer)
setwd('~/Desktop/GLIS Research/GLIS_research_project/data')
# ####################################################################
dt <- fread('knn_imputed_cn_data.csv')[,-1]
# sustainable value
dt[, `:=`(sus_val = rowSums(.SD, na.rm=T)), .SDcols=c(41,49:56)]
# aesthetic values
dt[, aes_val := rowSums(.SD, na.rm=T), .SDcols=c(42:43)]
#Green Consciousness
dt[, green_con := rowSums(.SD, na.rm=T), .SDcols=c(1:5)]
#Consumer Innovativeness
dt[, con_inno := rowSums(.SD, na.rm=T), .SDcols=c(50:56, 58:62)]
dt_individual <- dt[, c(65,41,49:56,42:43)]
dt_individual <- dt_individual[Q41.Sex < 3,]
dt_individual$Q41.Sex <- as.factor(ifelse(dt_individual$Q41.Sex<=1, "Male", "Female"))
dt_aes_sus  <- dt[, c(65,70,71)]
dt_aes_sus <- dt_aes_sus[Q41.Sex < 3,]
View(dt_individual)
dt_aes_sus  <- dt[, c(65,70,71)]
dt_aes_sus <- dt_aes_sus[Q41.Sex < 3,]
dt_aes_sus$Q41.Sex <- as.factor(ifelse(dt_aes_sus$Q41.Sex<=1, "Male", "Female"))
View(dt_aes_sus)
#Bayesian inference on Two Paired Means
dt_a_s <- dt[, c(65,70,71)]
dt_a_s[, .(score_sum = aes_val + sus_val)]
dt_a_s[, score_sum := aes_val + sus_val]
View(dt_a_s)
dt_a_s[, score_sum := aes_val + sus_val]
View(dt_a_s)
ggplot(dt_a_s, aes(x = Q41.Sex, y = score_sum)) +
geom_boxplot()
dt_a_s$Q41.Sex <- as.factor(dt_a_s$Q41.Sex)
ggplot(dt_a_s, aes(x = Q41.Sex, y = score_sum)) +
geom_boxplot()
View(dt_a_s)
#Bayesian inference for two independent means
dt_a_s <- dt[, c(65,70,71)]
dt_a_s[, score_sum := aes_val + sus_val]
dt_a_s[Q41.Sex <1.5, Q41.Sex:=1]
dt_a_s[Q41.Sex >= 1.5, Q41.Sex:21]
#Bayesian inference for two independent means
dt_a_s <- dt[, c(65,70,71)]
dt_a_s[, score_sum := aes_val + sus_val]
dt_a_s[Q41.Sex <1.5, Q41.Sex:=1]
dt_a_s[Q41.Sex >= 1.5, Q41.Sex:=2]
dt_a_s$Q41.Sex <- as.factor(dt_a_s$Q41.Sex)
ggplot(dt_a_s, aes(x = Q41.Sex, y = score_sum)) +
geom_boxplot()
bayes_inference(y = score_sum, x = Q41.Sex, data = dt_a_s,
statistic = "mean",
type = "ht", alternative = "twosided", null = 0,
prior = "JZS", rscale = 1,
method = "theoretical", show_plot = FALSE)
pacman::p_load(data.table, bit64, openxlsx, haven, dplyr, corrplot, zoo,
matrixStats, plotly, DAAG,PerformanceAnalytics,
BiocManager, ISLR, tree, rpart,rpart.plot, arsenal, rattle,
RColorBrewer, statsr)
bayes_inference(y = score_sum, x = Q41.Sex, data = dt_a_s,
statistic = "mean",
type = "ht", alternative = "twosided", null = 0,
prior = "JZS", rscale = 1,
method = "theoretical", show_plot = FALSE)
bayes_inference(y = score_sum, x = Q41.Sex, data = dt_a_s,
statistic = "mean",
type = "ht", alternative = "twosided", null = 0,
prior = "JZS", rscale = 1,
method = "theoretical")
bayes_inference(y = score_sum, x = Q41.Sex, data = dt_a_s,
statistic = "mean",
type = "ht", alternative = "twosided", null = 0,
prior = "JZS", rscale = sqrt(2)/2,
method = "theoretical")
bayes_inference(y = score_sum, x = Q41.Sex, data = dt_a_s,
statistic = "mean",
type = "ht", alternative = "twosided", null = 0,
prior = "JZS", rscale = sqrt(2)/2,
method = "theoretical", show_plot = FALSE)
1
bayes_inference(y = score_sum, x = Q41.Sex, data = dt_a_s,
statistic = "mean",
type = "ht", alternative = "twosided", null = 0,
prior = "JZS", rscale = 1,
method = "theoretical", show_plot = FALSE)
bayes_inference(y = score_sum, x = Q41.Sex, data = dt_a_s,
statistic = "mean",
type = "ci", mu_0 = 0,
prior = "JZS", rscale = 1,
method = "theoretical")
bayes_inference(y = score_sum, x = Q41.Sex, data = dt_a_s,
statistic = "mean",
type = "ci", mu_0 = 0,
prior = "JZS", rscale = 1,
method = "simulation")
View(dt_a_s)
bayes_inference(y = score_sum, x = Q41.Sex, data = dt_a_s,
statistic = "mean",
type = "ht", alternative = "twosided", null = 0,
prior = "JZS", rscale = 1,
method = "theoretical", show_plot = FALSE)
score_post <- bayes_inference(y = score_sum, x = Q41.Sex, data = dt_a_s,
statistic = "mean",
type = "ci", mu_0 = 0,
prior = "JZS", rscale = 1,
method = "simulation")
name(score_post)
names(score_post)
dt_male <- dt_a_s[Q41.Sex == 1,]
male_post <- bayes_inference(y = score_sum, data = dt_male,
statistic = "mean",
type = "ci", mu_0 = 0,
prior = "JZS", rscale = 1,
method = "simulation")
samples = as.data.frame(male_post$samples)
nsim = nrow(samples)
samples = mutate(samples, y_pred = rnorm(nsim, mu, sqrt(sig2)))
ggplot(data = samples, aes(x = y_pred)) +
geom_histogram(aes(y = ..density..), bins = 100) +
geom_density() +
xlab(expression(y[new]))
dplyr::select(samples, mu, y_pred) %>%
map(quantile, probs=c(0.025, 0.50, 0.975))
dplyr
pacman::p_load(data.table, bit64, openxlsx, haven, dplyr, corrplot, zoo,
matrixStats, plotly, DAAG,PerformanceAnalytics,
BiocManager, ISLR, tree, rpart,rpart.plot, arsenal, rattle,
RColorBrewer, statsr)
dplyr::select(samples, mu, y_pred) %>%
map(quantile, probs=c(0.025, 0.50, 0.975))
dplyr::select(samples, mu, y_pred)
map
pacman::p_load(data.table, bit64, openxlsx, haven, dplyr, corrplot, zoo,
matrixStats, plotly, DAAG,PerformanceAnalytics,
BiocManager, ISLR, tree, rpart,rpart.plot, arsenal, rattle,
RColorBrewer, statsr, tidyverse)
dplyr::select(samples, mu, y_pred) %>%
map(quantile, probs=c(0.025, 0.50, 0.975))
mean(dt_a_s$score_sum)
male_post <- bayes_inference(y = score_sum, data = dt_male,
statistic = "mean",
type = "ci", mu_0 = 43.9,
prior = "JZS", rscale = 1,
method = "simulation")
samples = as.data.frame(male_post$samples)
nsim = nrow(samples)
samples = mutate(samples, y_pred = rnorm(nsim, mu, sqrt(sig2)))
ggplot(data = samples, aes(x = y_pred)) +
geom_histogram(aes(y = ..density..), bins = 100) +
geom_density() +
xlab(expression(y[new]))
dplyr::select(samples, mu, y_pred) %>%
map(quantile, probs=c(0.025, 0.50, 0.975))
bayes_inference
install.packages(c("bit", "broom", "callr", "caTools", "farver", "foreign", "gh", "knitr", "ModelMetrics", "prettyunits", "pROC", "RcppArmadillo", "RCurl", "rlang", "rmarkdown", "SQUAREM", "stringi", "tidyr", "tidyselect", "tinytex", "vctrs", "xts"))
install.packages(c("bit", "broom", "callr", "caTools", "farver", "foreign", "gh", "knitr", "ModelMetrics", "prettyunits", "pROC", "RcppArmadillo", "RCurl", "rlang", "rmarkdown", "SQUAREM", "stringi", "tidyr", "tidyselect", "tinytex", "vctrs", "xts"))
install.packages(c("bit", "broom", "callr", "caTools", "farver", "foreign", "gh", "knitr", "ModelMetrics", "prettyunits", "pROC", "RcppArmadillo", "RCurl", "rlang", "rmarkdown", "SQUAREM", "stringi", "tidyr", "tidyselect", "tinytex", "vctrs", "xts"))
